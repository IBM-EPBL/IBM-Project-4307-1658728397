{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##**ASSIGNMENT_3** :- (Nithish.R.L)"
      ],
      "metadata": {
        "id": "pr6Qef1yG00u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtuD94MHCSgl",
        "outputId": "5362d4bc-f07c-40c8-97df-ee849278dbd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracting Data\n",
        "!unzip \"/content/drive/MyDrive/Colab Notebooks/Flowers-Dataset ( Splitted ).zip\""
      ],
      "metadata": {
        "id": "eIXc1DerGqBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Image Augmentation :"
      ],
      "metadata": {
        "id": "UARNlPiq8Y9t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFr6ERMd68L4"
      },
      "outputs": [],
      "source": [
        "#Import req. Lib.\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Augmentation On Training Variable\n",
        "train_datagen = ImageDataGenerator(rescale= 1./255,\n",
        "                 zoom_range=0.2,\n",
        "                 horizontal_flip =True)"
      ],
      "metadata": {
        "id": "2ac7KkgfgYdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Augmentation On Training Variable\n",
        "test_datagen = ImageDataGenerator(rescale= 1./255)"
      ],
      "metadata": {
        "id": "jfwbBT_xGyvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Augmentation On Training Variable\n",
        "ftrain = train_datagen.flow_from_directory('/content/Flowers-Dataset ( Splitted )/Training',\n",
        "                                           target_size=(64,64),\n",
        "                                           class_mode='categorical',\n",
        "                                           batch_size=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNZJULTnHt2N",
        "outputId": "f045f074-ac25-4a99-83b6-5189786d621c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4086 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Augmentation On Training Variable\n",
        "ftest = test_datagen.flow_from_directory('/content/Flowers-Dataset ( Splitted )/Testing',\n",
        "                                          target_size=(64,64),\n",
        "                                          class_mode='categorical',\n",
        "                                          batch_size=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfPQ1evFIzI2",
        "outputId": "b2618923-8a8e-4642-dcf1-0fa55af5fc9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 231 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Creating The Model  :"
      ],
      "metadata": {
        "id": "8MX6mdYeHuso"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding Layers :"
      ],
      "metadata": {
        "id": "U_C6yvyEQHjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import req. Lib.\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense"
      ],
      "metadata": {
        "id": "2Huu0RvYJvN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a CNN Block:\n",
        "model = Sequential() #intializing sequential model\n",
        "model.add(Convolution2D(32,(3,3),activation='relu', input_shape=(64,64,3))) #convolution layer\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) #Maxpooling layer\n",
        "model.add(Flatten()) #Flatten layer\n",
        "model.add(Dense(400,activation='relu')) #Hidden Layer 1\n",
        "model.add(Dense(200,activation='relu')) #Hidden Layer 2\n",
        "model.add(Dense(5,activation='softmax')) #Output Layer"
      ],
      "metadata": {
        "id": "lety6cYbK0t7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compiling :"
      ],
      "metadata": {
        "id": "Dz0o7IkdMGRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling The Model...\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "4N9ZKjgiMI0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fit / Train The Model :"
      ],
      "metadata": {
        "id": "8mdLB9__P3S2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Train Model:\n",
        "model.fit_generator(ftrain,\n",
        "                    steps_per_epoch=len(ftrain),\n",
        "                    epochs=10,\n",
        "                    validation_data=ftest,\n",
        "                    validation_steps=len(ftest))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Tps3On_P2fU",
        "outputId": "4df7a839-6503-4510-b6e5-0af255dfdf0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "41/41 [==============================] - 30s 711ms/step - loss: 1.3702 - accuracy: 0.4315 - val_loss: 1.2850 - val_accuracy: 0.5238\n",
            "Epoch 2/10\n",
            "41/41 [==============================] - 29s 701ms/step - loss: 1.0398 - accuracy: 0.5918 - val_loss: 1.3570 - val_accuracy: 0.5411\n",
            "Epoch 3/10\n",
            "41/41 [==============================] - 29s 701ms/step - loss: 0.9675 - accuracy: 0.6238 - val_loss: 1.4026 - val_accuracy: 0.5065\n",
            "Epoch 4/10\n",
            "41/41 [==============================] - 29s 701ms/step - loss: 0.8853 - accuracy: 0.6601 - val_loss: 1.2253 - val_accuracy: 0.5887\n",
            "Epoch 5/10\n",
            "41/41 [==============================] - 29s 703ms/step - loss: 0.8395 - accuracy: 0.6806 - val_loss: 1.1541 - val_accuracy: 0.5801\n",
            "Epoch 6/10\n",
            "41/41 [==============================] - 29s 701ms/step - loss: 0.7740 - accuracy: 0.6982 - val_loss: 1.2437 - val_accuracy: 0.5714\n",
            "Epoch 7/10\n",
            "41/41 [==============================] - 29s 701ms/step - loss: 0.7467 - accuracy: 0.7181 - val_loss: 1.1862 - val_accuracy: 0.6277\n",
            "Epoch 8/10\n",
            "41/41 [==============================] - 29s 697ms/step - loss: 0.6988 - accuracy: 0.7332 - val_loss: 1.1816 - val_accuracy: 0.6061\n",
            "Epoch 9/10\n",
            "41/41 [==============================] - 29s 700ms/step - loss: 0.6728 - accuracy: 0.7442 - val_loss: 1.2922 - val_accuracy: 0.6104\n",
            "Epoch 10/10\n",
            "41/41 [==============================] - 30s 721ms/step - loss: 0.6166 - accuracy: 0.7624 - val_loss: 1.3966 - val_accuracy: 0.5931\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd7e3c5eb90>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving The Model :"
      ],
      "metadata": {
        "id": "Cpt-Cr3nSmu5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Save Model\n",
        "model.save('flowers.h5')"
      ],
      "metadata": {
        "id": "06enLiatSloW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Testing The Model :"
      ],
      "metadata": {
        "id": "t3FejLP8Tn6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import req. Lib.\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "ALVcXMS4TnNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing No 1 :-\n",
        "img = image.load_img('/content/Flowers-Dataset ( Splitted )/Testing/daisy/34275662120_7757a15d07_n.jpg',target_size=(64,64)) #Reading image\n",
        "f = image.img_to_array(img) #Convertinng image to array\n",
        "f = np.expand_dims(f,axis=0) #Expanding dimensions\n",
        "pred = np.argmax(model.predict(f)) #predicting higher propability index\n",
        "op = ['daisy','dandelion','rose','sunflower','tulip'] #Creating List\n",
        "op[pred] #List indexing with output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "jOMmwMVZT5aa",
        "outputId": "79cea7d6-457e-4f40-a6bd-159d2b9194e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'daisy'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing No 2 :-\n",
        "img = image.load_img('/content/Flowers-Dataset ( Splitted )/Testing/sunflower/14121915990_4b76718077_m.jpg',target_size=(64,64)) #Reading image\n",
        "f = image.img_to_array(img) #Convertinng image to array\n",
        "f = np.expand_dims(f,axis=0) #Expanding dimensions\n",
        "pred = np.argmax(model.predict(f)) #predicting higher propability index\n",
        "op = ['daisy','dandelion','rose','sunflower','tulip'] #Creating List\n",
        "op[pred] #List indexing with output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "tL_w73-UVLqQ",
        "outputId": "0338c086-845e-44d9-b344-d4caad76906f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sunflower'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing No 3 :-\n",
        "img = image.load_img('/content/Flowers-Dataset ( Splitted )/Testing/tulip/19425920580_cdc8f49aed_n.jpg',target_size=(64,64)) #Reading image\n",
        "f = image.img_to_array(img) #Convertinng image to array\n",
        "f = np.expand_dims(f,axis=0) #Expanding dimensions\n",
        "pred = np.argmax(model.predict(f)) #predicting higher propability index\n",
        "op = ['daisy','dandelion','rose','sunflower','tulip'] #Creating List\n",
        "op[pred] #List indexing with output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "TPh9O_U_YrQK",
        "outputId": "58cd9ba0-3161-4823-8f04-02809aa60465"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tulip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the above three tests performed the Model has predicted the images correctly..!"
      ],
      "metadata": {
        "id": "YNOabfnCV4FX"
      }
    }
  ]
}